@online{DifferentTypesOfWrestling,
    author = "Nicolas Kohlhuber",
    title = "What are the differences between Freestyle and Greco-Roman wrestling?",
    url = "https://olympics.com/en/news/differences-between-freestyle-and-greco-roman-wrestling",
    year = {2023}
}

@book{cejudo2012wrestling,
  title={Wrestling for dummies},
  author={Cejudo, Henry},
  year={2012},
  publisher={John Wiley \& Sons}
}

@book{takagaki2012techniques,
  title={Techniques of Judo},
  author={Takagaki, Shinzo and Sharp, Harold E},
  year={2012},
  publisher={Tuttle Publishing}
}

@online{JohnDanaherJiuJitsuEvolution,
    title = "John Danaher Explains Evolution Of Leg Lock System",
    author = "Christopher Ming",
    url = "https://christopherming.com/danaher-leg-lock/",
    year = "2021"
}

@article{DefineComputerVision,
  title={Introduction to computer vision},
  author={Learned-Miller, Erik G},
  journal={University of Massachusetts, Amherst},
  year={2011}
}

@book{nielsen2015neural,
  title={Neural networks and deep learning},
  author={Nielsen, Michael A},
  volume={25},
  year={2015},
  publisher={Determination press San Francisco, CA, USA}
}

@INPROCEEDINGS{DefineHumanPoseEstimation,
  author={Saroja, M N and Baskaran, K R and Priyanka, P},
  booktitle={2021 International Conference on Advancements in Electrical, Electronics, Communication, Computing and Automation (ICAECA)}, 
  title={Human pose estimation approaches for human activity recognition}, 
  year={2021},
  volume={},
  number={},
  pages={1-4},
  doi={10.1109/ICAECA52838.2021.9675787}}


@online{PoorRefereeing,
    author = "PoorRefereeing"
}

@article{HumanPose2dvs3d,
    title = {A review of deep learning techniques for 2D and 3D human pose estimation},
    journal = {Image and Vision Computing},
    volume = {114},
    pages = {104282},
    year = {2021},
    issn = {0262-8856},
    doi = {https://doi.org/10.1016/j.imavis.2021.104282},
    url = {https://www.sciencedirect.com/science/article/pii/S0262885621001876},
    author = {Miniar {Ben Gamra} and Moulay A. Akhloufi},
    keywords = {2D and 3D human pose estimation, Single-person and multi-person pose estimation, Deep learning, CNN, Computer vision},
    abstract = {Inferring human pose from a monocular RGB image remains an interesting field of research in computer vision. It serves as a fundamental key for many real-world applications, including human-computer interaction, animation, and detecting abnormal or illegal human behavior. Despite the considerable progress made in this area during the last decade, the proposed methods face serious problems due to the huge variations in human appearance, occlusions, noisy backgrounds, viewpoints, and other factors that can change the context of the captured information. In this paper, we introduce a survey of state-of-the-art methods to highlight various research that have been proposed to tackle the 2D and 3D pose estimation tasks. Based on the number of persons in the image, two main pipelines are identified: single-person and multi-person methods. Each of these categories is divided into two groups according to the proposed architectures. Also, we provide a brief description of current datasets and the different metrics applied to evaluate the methods performances. Finally, we include a discussion about the advantages and disadvantages of the mentioned strategies.}
}

@book{ribeiro2008jiu,
  title={Jiu-jitsu university},
  author={Ribeiro, Saulo},
  year={2008},
  publisher={Victory Belt Publishing}
}

@article{ComputerVisionAndDeepLearning,
    author={Voulodimos, Athanasios
    and Doulamis, Nikolaos
    and Doulamis, Anastasios
    and Protopapadakis, Eftychios},
    title={Deep Learning for Computer Vision: A Brief Review},
    journal={Computational Intelligence and Neuroscience},
    year={2018},
    month={2},
    day={01},
    publisher={Hindawi},
    volume={2018},
    pages={7068349},
    abstract={Over the last years deep learning methods have been shown to outperform previous state-of-the-art machine learning techniques in several fields, with computer vision being one of the most prominent cases. This review paper provides a brief overview of some of the most significant deep learning schemes used in computer vision problems, that is, Convolutional Neural Networks, Deep Boltzmann Machines and Deep Belief Networks, and Stacked Denoising Autoencoders. A brief account of their history, structure, advantages, and limitations is given, followed by a description of their applications in various computer vision tasks, such as object detection, face recognition, action and activity recognition, and human pose estimation. Finally, a brief overview is given of future directions in designing deep learning schemes for computer vision problems and the challenges involved therein.},
    issn={1687-5265},
    doi={10.1155/2018/7068349},
    url={https://doi.org/10.1155/2018/7068349}
}

@online{HPEFitnessRehab,
    author = "Liubov Zatolokina",
    year = "2023", 
    title = "Using Human Pose Estimation in Fitness \& Rehab Therapy Apps",
    url = "https://mobidev.biz/blog/human-pose-estimation-technology-guide",
}

@online{HPEUltimateGuide,
    author = "Natassha Selvaraj",
    title = "Human Pose Estimation: Ultimate Guide [2023 edition]",
    year = "2023",
    url = "https://kili-technology.com/data-labeling/machine-learning/human-pose-estimation-ultimate-beginners-guide-2023-edition"
}

@online{HPEVisoAI,
    author = "Elisha Odemakinde",
    title = "Human Pose Estimation with Deep Learning – Ultimate Overview in 2024",
    url = "https://viso.ai/deep-learning/pose-estimation-ultimate-overview/",
    year = "2023"
}

@article{HPEDeepLearningMethods,
  title={Monocular human pose estimation: A survey of deep learning-based methods},
  author={Chen, Yucheng and Tian, Yingli and He, Mingyi},
  journal={Computer vision and image understanding},
  volume={192},
  pages={102897},
  year={2020},
  publisher={Elsevier}
}

% - \\\\\\\\ Past solutions (applied)

@inproceedings{IdentifyingBJJPositions,
    author = {Hudovernik, Valter and Skocaj, Danijel},
    title = {Video-Based Detection of Combat Positions and Automatic Scoring in Jiu-Jitsu},
    year = {2022},
    isbn = {9781450394888},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3552437.3555707},
    doi = {10.1145/3552437.3555707},
    abstract = {Due to the increasing capabilities of computer vision methods, it is now possible to apply them even to the most difficult scenarios, such as for vision-based analysis of a jiu-jitsu match. One of the biggest challenges of such scenarios are heavily occluded scenes. Jiu-jitsu is a grappling martial art in which athletes are interlocked in complex positions most of the time. This produces significant challenges for computer vision methods. We propose a method to track the athletes' poses even in such scenarios. The advantage of our method is that it combines positional, structural, and visual cues to overcome this problem and is able to cope with severe occlusions. We use this data to automatically predict combat positions at a high accuracy. Finally, we propose a novel approach for automatic scoring of a jiu-jitsu match from video using these predictions.},
    booktitle = {Proceedings of the 5th International ACM Workshop on Multimedia Content Analysis in Sports},
    pages = {55–63},
    numpages = {9},
    keywords = {automation, pose estimation, tracking, neural networks, jiu-jitsu, classification, sports, datasets},
    location = {Lisboa, Portugal},
    series = {MMSports '22}
}


@INPROCEEDINGS{KarateKata,
  author={Walid, Mazen and Ameen, Mostafa and Atia, Ayman},
  booktitle={2023 International Mobile, Intelligent, and Ubiquitous Computing Conference (MIUCC)}, 
  title={Real-time Detection of Taikyoku Shodan Karate Kata Poses Using Classical Machine Learning and Deep Learning Models}, 
  year={2023},
  volume={},
  number={},
  pages={15-20},
  doi={10.1109/MIUCC58832.2023.10278373}
}

@ARTICLE{PartAffinityFieldsBJJPaper,
  author={Cao, Zhe and Hidalgo, Gines and Simon, Tomas and Wei, Shih-En and Sheikh, Yaser},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={OpenPose: Realtime Multi-Person 2D Pose Estimation Using Part Affinity Fields}, 
  year={2021},
  volume={43},
  number={1},
  pages={172-186},
  doi={10.1109/TPAMI.2019.2929257}
}

@ARTICLE{WearableForceSensorsBJJPaper,
  author={Chi, E.H.},
  journal={IEEE Pervasive Computing}, 
  title={Introducing wearable force sensors in martial arts}, 
  year={2005},
  volume={4},
  number={3},
  pages={47-53},
  doi={10.1109/MPRV.2005.67}
}

@inproceedings{KarateCombatPunchAnticipationBJJPaper,
    author = {Echeverria, Jon and Santos, Olga C.},
    title = {Punch Anticipation in a Karate Combat with Computer Vision},
    year = {2021},
    isbn = {9781450383677},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3450614.3461688},
    doi = {10.1145/3450614.3461688},
    abstract = {Fighting in karate martial art requires great dexterity and ability of multiple physical and psychological factors. A key and fundamental skill for the success of this endeavor is the anticipation of the opponent's movements. Anticipation is an innate attribute, but it can also be worked on with training. Vision training, in the search for peripheral vision that allows the opponent's body to be monitored, is continuously worked on in martial arts training. Nonetheless, peripheral vision can be of use outside the martial arts domain, such as when driving (to be able to notice the environment) or reading (to increase reading speed). New technologies can bring new training methods that enhance peripheral vision by training motion anticipation. For this, a tool designed for karate training is used to evaluate if computer vision filters can facilitate motion anticipation performance in karate practice. Our research aims to model the interaction of the fighters in order to improve the body reading of the opponent as well as the dexterity in the anticipation of the attacks made by the opponent, aimed to build a personalized system for psychomotor learning. A user study is carried out to evaluate whether computer vision can be used to improve the prediction of punch attacks launched by the rival as well as the response time to them.},
    booktitle = {Adjunct Proceedings of the 29th ACM Conference on User Modeling, Adaptation and Personalization},
    pages = {61–67},
    numpages = {7},
    location = {Utrecht, Netherlands},
    series = {UMAP '21}
}

@Article{PsychomotorPerformanceKarateCombatBJJPaper,
    AUTHOR = {Echeverria, Jon and Santos, Olga C.},
    TITLE = {Toward Modeling Psychomotor Performance in Karate Combats Using Computer Vision Pose Estimation},
    JOURNAL = {Sensors},
    VOLUME = {21},
    YEAR = {2021},
    NUMBER = {24},
    ARTICLE-NUMBER = {8378},
    URL = {https://www.mdpi.com/1424-8220/21/24/8378},
    PubMedID = {34960464},
    ISSN = {1424-8220},
    ABSTRACT = {Technological advances enable the design of systems that interact more closely with humans in a multitude of previously unsuspected fields. Martial arts are not outside the application of these techniques. From the point of view of the modeling of human movement in relation to the learning of complex motor skills, martial arts are of interest because they are articulated around a system of movements that are predefined, or at least, bounded, and governed by the laws of Physics. Their execution must be learned after continuous practice over time. Literature suggests that artificial intelligence algorithms, such as those used for computer vision, can model the movements performed. Thus, they can be compared with a good execution as well as analyze their temporal evolution during learning. We are exploring the application of this approach to model psychomotor performance in Karate combats (called kumites), which are characterized by the explosiveness of their movements. In addition, modeling psychomotor performance in a kumite requires the modeling of the joint interaction of two participants, while most current research efforts in human movement computing focus on the modeling of movements performed individually. Thus, in this work, we explore how to apply a pose estimation algorithm to extract the features of some predefined movements of Ippon Kihon kumite (a one-step conventional assault) and compare classification metrics with four data mining algorithms, obtaining high values with them.},
    DOI = {10.3390/s21248378}
}

@inproceedings{OpenPoseMAPresentationBJJPaper,
    author = {Le, Van-Hung and Nguyen, Tuong-Thanh and Tran, Ngoc-Anh and Pham, Thanh-Cong},
    year = {2019},
    month = {09},
    pages = {76-81},
    title = {OpenPose’s Evaluation in The Video Traditional Martial Arts Presentation},
    doi = {10.1109/ISCIT.2019.8905243}
}

@article{TaekwondoActionRecognitionBJJPaper,
    author = {Liang, Jianqiao and Zuo, Guocai and Ding, Baiyuan},
    title = {Taekwondo Action Recognition Method Based on Partial Perception Structure Graph Convolution Framework},
    year = {2022},
    issue_date = {2022},
    publisher = {Hindawi Limited},
    address = {London, GBR},
    volume = {2022},
    issn = {1058-9244},
    url = {https://doi.org/10.1155/2022/1838468},
    doi = {10.1155/2022/1838468},
    abstract = {Action recognition in Taekwondo competitions and training is an important task, which can provide a very valuable reference factor for technicians, athletes, and coaches. We propose a graph convolution framework with part of the perception structure to recognize, decompose, and analyze Taekwondo actions. Taking advantage of the long short-term memory of a part of the perception structure, the recognized Taekwondo actions are marked in time series, and then features are extracted from the graph convolution level to obtain the spatial and temporal associations between joints. Predict the action category and perform score matching based on the manual tag database. Finally, it is verified on our self-made Taekwondo competition data set. Our method has an average accuracy of 90\% in action recognition, and an average action score matching rate of 74.6\%. The accuracy of action recognition is high, which provides great assistance to Taekwondo e training and competitions.},
    journal = {Sci. Program.},
    month = {1},
    numpages = {10}
}

@article{GestureEstimation3DMABJJPaper,
    title = {Gesture estimation for 3D martial arts based on neural network},
    journal = {Displays},
    volume = {72},
    pages = {102138},
    year = {2022},
    issn = {0141-9382},
    doi = {https://doi.org/10.1016/j.displa.2021.102138},
    url = {https://www.sciencedirect.com/science/article/pii/S0141938221001372},
    author = {Mengmeng Liu and Jun Zhang},
    keywords = {Convolutional Neural Network (CNN), Three-dimensional martial arts gestures, Gestures estimation, Morphological topological structure, Joints},
    abstract = {A 3D martial arts gestures estimation method is proposed, for it is difficult to accurately describe the gestures, which is caused by the high degree of freedom and high similarity of 3D martial arts gestures. This method is combined with finger kinematics analysis model. And beyond that, it is based on the morphological topological structure of hand and combined with the CNN neural network. Firstly, the CNN is used to extract and classify 3D gesture features of martial arts. Then, using the morphological topological structure of hands to simulate the dependence of hand joints, and the 3D coordinates of hand joints were obtained. Finally, the attitude regression module is used to realize the attitude estimation of martial arts gesture action. Simulation results show that the accuracy of gesture estimation can be improved through cascade splicing in this research. Compared with existing 3D gesture estimation methods such as V2V, Pose-REN and CrossInfoNet, the proposed method performs better in MSE and FS indicators. It has lower estimation errors and an inference speed of 220.7 frames per second. In addition, the three-dimensional visualization results show that the predicted joint points obtained by the proposed estimation method coincide with the labeled joint points, and there is no occlusion. So it is proved that the proposed method is feasible, and it can be used to estimate martial arts gestures in the future.}
}

@online {taikyoku1,
    url = "https://www.shotokankarateonline.com/3rd-kyu-brown-belt/taikyoku-shodan-kata-step-by-step/"
}

@online {taikyoku2,
    url = "https://shotokankaratecsl.com/Kata%2027%20-%20Taikyoku%20Shodan.html"
}

@online {taikyoku3,
    url = "https://www.shotokankarate.ca/shotokan-katas/view/4-taikyoku-shodan"
}

@misc{TransformersIntro,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{xu2022vitpose,
      title={ViTPose: Simple Vision Transformer Baselines for Human Pose Estimation}, 
      author={Yufei Xu and Jing Zhang and Qiming Zhang and Dacheng Tao},
      year={2022},
      eprint={2204.12484},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{devries2017dataset,
      title={Dataset Augmentation in Feature Space}, 
      author={Terrance DeVries and Graham W. Taylor},
      year={2017},
      eprint={1702.05538},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}